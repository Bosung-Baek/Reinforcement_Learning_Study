{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = Dense(24, activation='relu')\n",
    "        self.fc2 = Dense(24, activation='relu')\n",
    "        self.fc_out = Dense(action_size,\n",
    "                            kernel_initializer=RandomUniform(-1e-3, 1e-3))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        q = self.fc_out(x)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:   0 | score -62.00 | score avg -62.00 | memory length:  200 | epsilon: 1.0000\n",
      "episode:   1 | score -74.00 | score avg -63.20 | memory length:  400 | epsilon: 1.0000\n",
      "episode:   2 | score -50.00 | score avg -61.88 | memory length:  600 | epsilon: 1.0000\n",
      "episode:   3 | score -64.00 | score avg -62.09 | memory length:  800 | epsilon: 1.0000\n",
      "episode:   4 | score -20.00 | score avg -57.88 | memory length: 1000 | epsilon: 0.9990\n",
      "episode:   5 | score -62.00 | score avg -58.29 | memory length: 1200 | epsilon: 0.8178\n",
      "episode:   6 | score -22.00 | score avg -54.67 | memory length: 1400 | epsilon: 0.6695\n",
      "episode:   7 | score -36.00 | score avg -52.80 | memory length: 1600 | epsilon: 0.5481\n",
      "episode:   8 | score -14.00 | score avg -48.92 | memory length: 1800 | epsilon: 0.4487\n",
      "episode:   9 | score 0.00 | score avg -44.03 | memory length: 2000 | epsilon: 0.3673\n",
      "episode:  10 | score 18.00 | score avg -37.82 | memory length: 2000 | epsilon: 0.3007\n",
      "episode:  11 | score 40.00 | score avg -30.04 | memory length: 2000 | epsilon: 0.2462\n",
      "episode:  12 | score 4795.00 | score avg 452.46 | memory length: 2000 | epsilon: 0.2015\n",
      "episode:  13 | score 2.00 | score avg 407.42 | memory length: 2000 | epsilon: 0.1650\n",
      "episode:  14 | score 2.00 | score avg 366.87 | memory length: 2000 | epsilon: 0.1351\n",
      "episode:  15 | score 44.00 | score avg 334.59 | memory length: 2000 | epsilon: 0.1106\n",
      "episode:  16 | score 48.00 | score avg 305.93 | memory length: 2000 | epsilon: 0.0905\n",
      "episode:  17 | score 40.00 | score avg 279.34 | memory length: 2000 | epsilon: 0.0741\n",
      "episode:  18 | score 30.00 | score avg 254.40 | memory length: 2000 | epsilon: 0.0607\n",
      "episode:  19 | score 38.00 | score avg 232.76 | memory length: 2000 | epsilon: 0.0497\n",
      "episode:  20 | score 26.00 | score avg 212.09 | memory length: 2000 | epsilon: 0.0407\n",
      "episode:  21 | score 34.00 | score avg 194.28 | memory length: 2000 | epsilon: 0.0333\n",
      "episode:  22 | score 84.00 | score avg 183.25 | memory length: 2000 | epsilon: 0.0272\n",
      "episode:  23 | score 74.00 | score avg 172.32 | memory length: 2000 | epsilon: 0.0223\n",
      "episode:  24 | score 24.00 | score avg 157.49 | memory length: 2000 | epsilon: 0.0183\n",
      "episode:  25 | score 56.00 | score avg 147.34 | memory length: 2000 | epsilon: 0.0149\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m     env\u001b[39m.\u001b[39mrender()\n\u001b[0;32m     85\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mget_action(state)\n\u001b[1;32m---> 86\u001b[0m next_state, reward, done1, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     88\u001b[0m next_state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(next_state, [\u001b[39m1\u001b[39m, state_size])\n\u001b[0;32m     91\u001b[0m next_position \u001b[39m=\u001b[39m next_state[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bosung\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m     \u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\bosung\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\bosung\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\bosung\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\classic_control\\mountain_car.py:148\u001b[0m, in \u001b[0;36mMountainCarEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m (position, velocity)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 148\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32), reward, terminated, \u001b[39mFalse\u001b[39;00m, {}\n",
      "File \u001b[1;32mc:\\Users\\bosung\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\classic_control\\mountain_car.py:266\u001b[0m, in \u001b[0;36mMountainCarEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m\"\u001b[39;49m\u001b[39mrender_fps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    267\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mflip()\n\u001b[0;32m    269\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.render = False\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.model = DQN(action_size)\n",
    "        self.target_model = DQN(action_size)\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        self.update_target_model()\n",
    "        \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model(state)\n",
    "            return np.argmax(q_value[0])\n",
    "        \n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([sample[0][0] for sample in mini_batch])\n",
    "        actions = np.array([sample[1] for sample in mini_batch])\n",
    "        rewards = np.array([sample[2] for sample in mini_batch])\n",
    "        next_states = np.array([sample[3][0] for sample in mini_batch])\n",
    "        dones = np.array([sample[4] for sample in mini_batch])\n",
    "        \n",
    "        model_params = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicts = self.model(states)\n",
    "            \n",
    "            one_hot_action = tf.one_hot(actions, self.action_size)\n",
    "            predicts = tf.reduce_sum(one_hot_action * predicts, axis=1)            \n",
    "            \n",
    "            target_predicts = self.target_model(next_states)\n",
    "            target_predicts = tf.stop_gradient(target_predicts)\n",
    "            \n",
    "            max_q = np.amax(target_predicts, axis=-1)\n",
    "            targets = rewards + (1 - dones) * self.discount_factor * max_q\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.square(targets - predicts))\n",
    "            \n",
    "        grads = tape.gradient(loss, model_params)\n",
    "        self.optimizer.apply_gradients(zip(grads, model_params))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('MountainCar-v0', render_mode='human')\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    \n",
    "    agent = Agent(state_size, action_size)\n",
    "    \n",
    "    scores, episodes = [], []\n",
    "    score_avg = 0\n",
    "    \n",
    "    num_episode = 1000\n",
    "    for e in range(num_episode):\n",
    "        done= False\n",
    "        score = 0\n",
    "        state = env.reset()[0]\n",
    "        \n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        \n",
    "        \n",
    "        \n",
    "        while not done:\n",
    "            if agent.render==True and e % 10 == 0:\n",
    "                env.render()\n",
    "                \n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done1, done, _ = env.step(action)\n",
    "            \n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            \n",
    "            \n",
    "            next_position = next_state[0, 0]\n",
    "            current_position = state[0, 0]\n",
    "\n",
    "            # 수정된 보상 계산\n",
    "            if next_state[0, 0] >= 0.5:\n",
    "                reward = 100  # 목표 지점에 도달한 경우\n",
    "            else:\n",
    "                if next_state[0, 1]<0 and action ==0:\n",
    "                    reward = 1\n",
    "                elif next_state[0, 1]>0 and action ==2:\n",
    "                    reward = 1\n",
    "                else:\n",
    "                    reward = -1\n",
    "                \n",
    "                \n",
    "            score += reward\n",
    "            \n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            if len(agent.memory) >= agent.train_start:\n",
    "                agent.train_model()\n",
    "                \n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                if done1:\n",
    "                    agent.update_target_model()\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print(\"episode: {:3d} | score {:3.2f} | score avg {:3.2f} | memory length: {:4d} | epsilon: {:.4f}\".format(\n",
    "                    e, score, score_avg, len(agent.memory), agent.epsilon))\n",
    "\n",
    "\n",
    "                \n",
    "                if score_avg > 5000:\n",
    "                    #save model\n",
    "                    agent.model.save_weights(\"./save_model/model\", save_format=\"tf\")\n",
    "                    sys.exit()\n",
    "                    \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:   0 | score: 48.608613\n",
      "episode:   1 | score: 35.321195\n",
      "episode:   2 | score: 41.176656\n",
      "episode:   3 | score: 34.394358\n",
      "episode:   4 | score: 48.515119\n"
     ]
    }
   ],
   "source": [
    "# play saved model\n",
    "agent.model.load_weights(\"./save_model/model\")\n",
    "agent.epsilon = 0.01\n",
    "\n",
    "plt.plot(episodes, scores, 'b')\n",
    "plt.show()\n",
    "\n",
    "for e in range(5):\n",
    "    \n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()[0]\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, _, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        if next_state[0, 0] >= 0.5:\n",
    "                reward = 1  # 목표 지점에 도달한 경우\n",
    "        else:\n",
    "            if next_state[0, 0]<0:\n",
    "                reward = next_state[0, 0]*0.01\n",
    "            else:\n",
    "                reward = next_state[0, 0]*0.1 # 실패한 경우\n",
    "                \n",
    "        score += reward\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode: {:3d} | score: {:3f}\".format(e, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
