{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 가치 함수\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "48\n",
      "\n",
      "무작위 정책으로 수렴할 때까지 반복한 가치 함수\n",
      "[[ 0.         -2.80432336 -3.26083989 -2.13041589]\n",
      " [-2.80432336 -4.95647453 -5.10864671 -3.26083989]\n",
      " [-3.26083989 -5.10864671 -4.95647453 -2.80432336]\n",
      " [-2.13041589 -3.26083989 -2.80432336  0.        ]]\n",
      "\n",
      "가치 함수로부터 행동을 결정하는 정책\n",
      "[['* ' '← ' '→ ' '↓←']\n",
      " ['↑ ' '↑←' '↑→' '↑ ']\n",
      " ['↓ ' '↓←' '↓→' '↓ ']\n",
      " ['↑→' '← ' '→ ' '* ']]\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.v = np.zeros((4, 4))\n",
    "\n",
    "    def update(self):\n",
    "        # 새로운 v와 기존의 v가 거의 같아질 때까지 반복\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            \n",
    "            new_v = np.zeros((4, 4))\n",
    "            for row in range(4):\n",
    "                for col in range(4):\n",
    "                    if row == 0 and col == 0 or row == 3 and col == 3:\n",
    "                        continue\n",
    "                    \n",
    "                    new_v[row, col] = self.get_new_v(row, col)    \n",
    "            cnt +=1\n",
    "            if np.sum(np.abs(self.v - new_v)) < 1e-4:\n",
    "                print(cnt)\n",
    "                break\n",
    "\n",
    "            self.v = new_v\n",
    "\n",
    "    def get_new_v(self, row, col):\n",
    "        # update 함수를 위한 각 상태에 대한 다음 가치 함수의 값을 가져옴\n",
    "        k = 0\n",
    "        action_set = {0: [-1, 0], 1: [1, 0], 2: [0, -1], 3: [0, 1]}\n",
    "        for action in range(4):\n",
    "            new_row = row + action_set[action][0]\n",
    "            new_col = col + action_set[action][1]\n",
    "            if new_row < 0 or new_col < 0 or new_row > 3 or new_col > 3:\n",
    "                continue\n",
    "            k += -1 + self.v[new_row, new_col]\n",
    "            \n",
    "        return k/4\n",
    "\n",
    "    def get_policy(self):\n",
    "        action_table = {0: [-1, 0], 1: [1, 0], 2: [0, -1], 3: [0, 1]}\n",
    "        dir_table = {0: \"↑\", 1: \"↓\", 2: \"←\", 3: \"→\"}\n",
    "        direction_list = []\n",
    "        for row in range(4):\n",
    "            direction_list_row = []\n",
    "            for col in range(4):\n",
    "                if row == 0 and col == 0 or row == 3 and col == 3:\n",
    "                    direction_list_row.append(\"* \")\n",
    "                    continue\n",
    "                direction = \"\"\n",
    "                action_value = []\n",
    "                for action in range(4):\n",
    "                    row_tar = row + action_table[action][0]\n",
    "                    col_tar = col + action_table[action][1]\n",
    "\n",
    "                    if row_tar < 0 or row_tar > 3 or col_tar < 0 or col_tar > 3:\n",
    "                        action_value.append(-999)\n",
    "                    else:\n",
    "                        action_value.append(self.v[row_tar, col_tar])\n",
    "\n",
    "                max_idx_list = np.argwhere(np.isclose(action_value, np.max(action_value))).flatten().tolist()\n",
    "\n",
    "                for i in max_idx_list:\n",
    "                    direction += dir_table[i]\n",
    "                direction += \" \" * (2-len(max_idx_list))\n",
    "                direction_list_row.append(direction)\n",
    "            direction_list.append(direction_list_row)\n",
    "        return np.array(direction_list)\n",
    "\n",
    "\n",
    "env = Environment()\n",
    "print(\"초기 가치 함수\")\n",
    "print(env.v)\n",
    "\n",
    "env.update()\n",
    "print(\"\\n무작위 정책으로 수렴할 때까지 반복한 가치 함수\")\n",
    "print(env.v)\n",
    "\n",
    "print(\"\\n가치 함수로부터 행동을 결정하는 정책\")\n",
    "print(env.get_policy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
